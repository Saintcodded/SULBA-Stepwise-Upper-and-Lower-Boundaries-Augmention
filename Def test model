import torch
import numpy as np

from sklearn.metrics import (
    accuracy_score,
    roc_auc_score,
    f1_score,
    classification_report
)


def test_model(model, test_loader, training_time):
    """
    Test-time evaluation for multi-class classification.

    Args:
        model (nn.Module): Trained model
        test_loader (DataLoader): Test data loader
        training_time (float): Total training time in seconds
    """
    model.eval()

    all_labels = []
    all_preds = []
    all_probs = []

    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device).squeeze().long()

            with torch.cuda.amp.autocast():
                outputs = model(images)

            probs = torch.softmax(outputs, dim=1)
            preds = torch.argmax(outputs, dim=1)

            all_labels.append(labels.cpu())
            all_preds.append(preds.cpu())
            all_probs.append(probs.cpu())

    # Concatenate tensors and convert to numpy
    all_labels = torch.cat(all_labels).numpy()
    all_preds = torch.cat(all_preds).numpy()
    all_probs = torch.cat(all_probs).numpy()

    # =========================
    # Metrics
    # =========================
    accuracy = accuracy_score(all_labels, all_preds)
    auroc = roc_auc_score(all_labels, all_probs, multi_class="ovr")
    f1 = f1_score(all_labels, all_preds, average="weighted")

    # =========================
    # Reporting
    # =========================
    print("\nTest Results")
    print("-" * 40)
    print(f"Total Training Time: {training_time:.2f} seconds")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"AUROC (OvR): {auroc:.4f}")
    print(f"F1 Score (weighted): {f1:.4f}")

    print("\nClassification Report:")
    print(classification_report(all_labels, all_preds, digits=4))

    return {
        "accuracy": accuracy,
        "auroc": auroc,
        "f1_weighted": f1,
        "training_time": training_time,
    }
