import time
import torch
import numpy as np
import torch.nn as nn
from tqdm import tqdm
import torch.optim as optim
from torch.cuda.amp import autocast, GradScaler
from sklearn.metrics import (accuracy_score, roc_auc_score, f1_score, classification_report)


# ========== Train Model (Task = Classification) ==========
def train_model(model, train_loader, val_loader):
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, fused=True)
    scaler = torch.cuda.amp.GradScaler()

    best_val_acc = 0.0
    best_val_loss = float("inf")
    best_epoch = 0

    train_losses, val_losses = [], []
    train_accs, val_accs = [], []

    start_time = time.time()

    for epoch in range(NUM_EPOCHS):
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for images, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS}"):
            images = images.to(device)
            labels = labels.to(device).squeeze().long()

            if labels.numel() == 0:
                continue

            optimizer.zero_grad(set_to_none=True)

            with torch.cuda.amp.autocast():
                outputs = model(images)
                loss = criterion(outputs, labels)

            scaler.scale(loss).backward()

            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)

            scaler.step(optimizer)
            scaler.update()

            running_loss += loss.item() * images.size(0)

            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        epoch_train_loss = running_loss / len(train_loader.dataset)
        epoch_train_acc = correct / total

        train_losses.append(epoch_train_loss)
        train_accs.append(epoch_train_acc)

        # Validation
        val_loss, val_acc = evaluate(model, val_loader, criterion)
        val_losses.append(val_loss)
        val_accs.append(val_acc)

        print(
            f"Epoch {epoch+1}/{NUM_EPOCHS} | "
            f"Train Loss: {epoch_train_loss:.4f}, Acc: {epoch_train_acc:.4f} | "
            f"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}"
        )

        # Save best model
        if (val_acc > best_val_acc) or (
            val_acc == best_val_acc and val_loss < best_val_loss
        ):
            best_val_acc = val_acc
            best_val_loss = val_loss
            best_epoch = epoch + 1
            torch.save(model.state_dict(), MODEL_SAVE_PATH)
            print(f"âœ“ New best model saved at epoch {best_epoch}")

    training_time = time.time() - start_time

    print(
        f"\nTraining completed in {training_time//60:.0f}m {training_time%60:.0f}s\n"
        f"Best epoch: {best_epoch} | "
        f"Val Acc: {best_val_acc:.4f}, Val Loss: {best_val_loss:.4f}"
    )

    return train_losses, val_losses, train_accs, val_accs, training_time


############################################################################
# ========== Test Model (Task = Classification) ==========

def test_model(model, test_loader, training_time):
    """
    Test-time evaluation for multi-class classification.

    Args:
        model (nn.Module): Trained model
        test_loader (DataLoader): Test data loader
        training_time (float): Total training time in seconds
    """
    model.eval()

    all_labels = []
    all_preds = []
    all_probs = []

    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device).squeeze().long()

            with torch.cuda.amp.autocast():
                outputs = model(images)

            probs = torch.softmax(outputs, dim=1)
            preds = torch.argmax(outputs, dim=1)

            all_labels.append(labels.cpu())
            all_preds.append(preds.cpu())
            all_probs.append(probs.cpu())

    # Concatenate tensors and convert to numpy
    all_labels = torch.cat(all_labels).numpy()
    all_preds = torch.cat(all_preds).numpy()
    all_probs = torch.cat(all_probs).numpy()

    # =========================
    # Metrics
    # =========================
    accuracy = accuracy_score(all_labels, all_preds)
    auroc = roc_auc_score(all_labels, all_probs, multi_class="ovr")
    f1 = f1_score(all_labels, all_preds, average="weighted")

    # =========================
    # Reporting
    # =========================
    print("\nTest Results")
    print("-" * 40)
    print(f"Total Training Time: {training_time:.2f} seconds")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"AUROC (OvR): {auroc:.4f}")
    print(f"F1 Score (weighted): {f1:.4f}")

    print("\nClassification Report:")
    print(classification_report(all_labels, all_preds, digits=4))

    return {
        "accuracy": accuracy,
        "auroc": auroc,
        "f1_weighted": f1,
        "training_time": training_time,
    }

