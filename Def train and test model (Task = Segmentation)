import time
import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
import segmentation_models_pytorch as smp


# ========== Calculate Metrics ==========
def calculate_metrics(outputs, masks, num_classes):
    """
    Standard multiclass segmentation metrics using SMP.
    """
    if masks.dim() == 3:
        masks = masks.unsqueeze(1)  # [B, 1, H, W]

    preds = torch.argmax(outputs, dim=1, keepdim=True)

    tp, fp, fn, tn = smp.metrics.get_stats(
        preds,
        masks.long(),
        mode="multiclass",
        num_classes=num_classes,
    )

    iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction="macro-imagewise")
    precision = smp.metrics.precision(tp, fp, fn, tn, reduction="macro-imagewise")
    recall = smp.metrics.recall(tp, fp, fn, tn, reduction="macro-imagewise")
    f1 = smp.metrics.f1_score(tp, fp, fn, tn, reduction="macro-imagewise")

    return iou, precision, recall, f1


# ========== Train Model (Task = Segmentation) ==========
def train_segmentation_model(
    model,
    train_loader,
    val_loader,
    device,
    num_epochs,
    learning_rate,
    num_classes,
    model_save_path,
):
    # =========================
    # Setup
    # =========================
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)

    best_val_iou = 0.0
    best_epoch = 0

    history = {
        "train_loss": [],
        "val_loss": [],
        "train_iou": [],
        "val_iou": [],
        "train_precision": [],
        "val_precision": [],
        "train_recall": [],
        "val_recall": [],
        "train_f1": [],
        "val_f1": [],
    }

    start_time = time.time()

    # =========================
    # Epoch loop
    # =========================
    for epoch in range(num_epochs):
        print(f"\nEpoch {epoch + 1}/{num_epochs}")

        # =========================
        # Training phase
        # =========================
        model.train()

        train_loss = 0.0
        train_iou = 0.0
        train_precision = 0.0
        train_recall = 0.0
        train_f1 = 0.0

        for images, masks in tqdm(train_loader, desc="Training"):
            images = images.to(device)
            masks = masks.to(device).long()

            if masks.dim() == 3:
                masks = masks.unsqueeze(1)

            optimizer.zero_grad()

            outputs = model(images)
            loss = criterion(outputs, masks.squeeze(1))

            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()

            with torch.no_grad():
                iou, prec, rec, f1 = calculate_metrics(
                    outputs, masks, num_classes
                )

            train_loss += loss.item()
            train_iou += iou.item()
            train_precision += prec.item()
            train_recall += rec.item()
            train_f1 += f1.item()

        num_train_batches = len(train_loader)
        train_loss /= num_train_batches
        train_iou /= num_train_batches
        train_precision /= num_train_batches
        train_recall /= num_train_batches
        train_f1 /= num_train_batches

        # =========================
        # Validation phase
        # =========================
        model.eval()

        val_loss = 0.0
        val_iou = 0.0
        val_precision = 0.0
        val_recall = 0.0
        val_f1 = 0.0

        with torch.no_grad():
            for images, masks in tqdm(val_loader, desc="Validation"):
                images = images.to(device)
                masks = masks.to(device).long()

                if masks.dim() == 3:
                    masks = masks.unsqueeze(1)

                outputs = model(images)
                loss = criterion(outputs, masks.squeeze(1))

                iou, prec, rec, f1 = calculate_metrics(
                    outputs, masks, num_classes
                )

                val_loss += loss.item()
                val_iou += iou.item()
                val_precision += prec.item()
                val_recall += rec.item()
                val_f1 += f1.item()

        num_val_batches = len(val_loader)
        val_loss /= num_val_batches
        val_iou /= num_val_batches
        val_precision /= num_val_batches
        val_recall /= num_val_batches
        val_f1 /= num_val_batches

        # =========================
        # Logging
        # =========================
        history["train_loss"].append(train_loss)
        history["val_loss"].append(val_loss)
        history["train_iou"].append(train_iou)
        history["val_iou"].append(val_iou)
        history["train_precision"].append(train_precision)
        history["val_precision"].append(val_precision)
        history["train_recall"].append(train_recall)
        history["val_recall"].append(val_recall)
        history["train_f1"].append(train_f1)
        history["val_f1"].append(val_f1)

        print(
            f"Train | Loss: {train_loss:.4f}, IoU: {train_iou:.4f}, F1: {train_f1:.4f}"
        )
        print(
            f"Val   | Loss: {val_loss:.4f}, IoU: {val_iou:.4f}, F1: {val_f1:.4f}"
        )

        # =========================
        # Save best model
        # =========================
        if val_iou > best_val_iou:
            best_val_iou = val_iou
            best_epoch = epoch + 1
            torch.save(model.state_dict(), model_save_path)
            print(f"âœ” Best model saved (epoch {best_epoch})")

    total_time = time.time() - start_time
    print(
        f"\nTraining completed in {total_time:.2f}s "
        f"({total_time / 60:.2f} minutes)"
    )
    print(f"Best validation IoU: {best_val_iou:.4f} at epoch {best_epoch}")

    return history, total_time


# ========== Test Model (task = Segmentation) ==========
def test_segmentation_model(
    model,
    test_loader,
    device,
    num_classes,
    criterion,
):
    model.eval()

    test_metrics = {
        "loss": 0.0,
        "iou": 0.0,
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
    }

    with torch.no_grad():
        for images, masks in tqdm(test_loader, desc="Testing"):
            images = images.to(device)
            masks = masks.to(device).long()

            if masks.dim() == 3:
                masks = masks.unsqueeze(1)

            outputs = model(images)
            loss = criterion(outputs, masks.squeeze(1))

            iou, prec, rec, f1 = calculate_metrics(
                outputs, masks, num_classes
            )

            test_metrics["loss"] += loss.item()
            test_metrics["iou"] += iou.item()
            test_metrics["precision"] += prec.item()
            test_metrics["recall"] += rec.item()
            test_metrics["f1"] += f1.item()

    num_batches = len(test_loader)
    for key in test_metrics:
        test_metrics[key] /= num_batches

    print("\n" + "=" * 60)
    print("FINAL TEST RESULTS")
    print("=" * 60)
    print(f"Loss:        {test_metrics['loss']:.4f}")
    print(f"IoU:         {test_metrics['iou']:.4f}")
    print(f"Precision:   {test_metrics['precision']:.4f}")
    print(f"Recall:      {test_metrics['recall']:.4f}")
    print(f"F1-score:    {test_metrics['f1']:.4f}")
    print("=" * 60)

    return test_metrics
