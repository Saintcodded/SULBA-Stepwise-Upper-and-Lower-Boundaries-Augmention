import timm
import torchvision
from torchvision import models
import monai.networks.nets as monai_nets
import segmentation_models_pytorch as smp
from torchvision.models.swin_transformer import Swin_T_Weights
from torchvision.models.video import swin3d_t, Swin3D_T_Weights


#############################################################
#========== Classification Models ==========

# ========== ResNet18 ==========
def ResNet18():
    # Load ResNet18 WITHOUT pretrained weights
    model = models.resnet18(pretrained=False)
    
    # ResNet18 first conv layer already expects 3-channel input

    # Modify final layer for number of classes
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, NUM_CLASSES)
    
    return model

# ========== ResNet18 (with Pretrained weights)==========
def ResNet18():
    model = models.resnet18(pretrained=True)
    
    # Modify first layer for our input size
    original_first_conv = model.conv1
    
    # Create new first layer with smaller kernel for 64x64 input
    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
    
    # Initialize with pretrained weights
    with torch.no_grad():
        original_weights = original_first_conv.weight.data
        avg_weights = original_weights.mean(dim=1, keepdim=True)
        
        # Interpolate weights from 7x7 to 3x3
        avg_weights = torch.nn.functional.interpolate(
            avg_weights, 
            size=(3, 3), 
            mode='bilinear', 
            align_corners=False
        )
        
        # Check if grayscale and adjust weight initialization
        if model.conv1.weight.data.shape[1] == 1:  # Grayscale (1 channel)
            # For grayscale: use average of all channels
            model.conv1.weight.data[:,:1,:,:] = avg_weights
        else:  # Color (3 channels)
            # Original logic for 3-channel input
            model.conv1.weight.data[:,:3,:,:] = avg_weights.repeat(1, 3, 1, 1)
    
    # Modify final layer for number of classes
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, NUM_CLASSES)
    
    return model


# ========== MobileNetV3_small ==========
def MobileNetV3_small():
    # Load MobileNetV3 Small WITHOUT pretrained weights
    model = models.mobilenet_v3_small(pretrained=False)
    
    # MobileNetV3 Small first conv layer (already configured for 3-channel input)
    
    # Modify final layer for number of classes
    num_ftrs = model.classifier[-1].in_features
    model.classifier[-1] = nn.Linear(num_ftrs, NUM_CLASSES)
    
    return model

# ========== MobileNetV3_small (with Pretrained Weight)==========
def MobileNetV3_small():
    # Load MobileNetV3 Small with pretrained weights (modern syntax)
    model = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)
    
    # MobileNetV3 first layer - access the parameters directly
    original_first_block = model.features[0]
    
    # Create new Conv2d layer with correct input channels
    new_conv_layer = nn.Conv2d(
        3, 16, 
        kernel_size=3, 
        stride=2,
        padding=1, 
        bias=False
    )
    
    # Initialize with pretrained weights
    with torch.no_grad():
        # The Conv2dNormActivation stores weights in its parameters
        # Try different ways to access the conv weights
        if hasattr(original_first_block, '0'):  # If it's a sequential
            original_weights = original_first_block[0].weight.data
        else:
            # Try to get the weight parameter directly
            for name, param in original_first_block.named_parameters():
                if 'weight' in name and param.dim() == 4:  # Conv weight
                    original_weights = param.data
                    break
        
        avg_weights = original_weights.mean(dim=1, keepdim=True)
        avg_weights = torch.nn.functional.interpolate(
            avg_weights, 
            size=(3, 3), 
            mode='bilinear', 
            align_corners=False
        )
        new_conv_layer.weight.data[:,:3,:,:] = avg_weights.repeat(1, 3, 1, 1)
    
    # Replace the entire first block
    model.features[0] = new_conv_layer
    
    # Modify final layer for number of classes
    num_ftrs = model.classifier[-1].in_features
    model.classifier[-1] = nn.Linear(num_ftrs, NUM_CLASSES)
    
    return model


# ========== r3d_18 ==========
def r3d_18():
    # Load R3D model for 3D data
    model = torchvision.models.video.r3d_18(pretrained=True)
    
    original_first_conv = model.stem[0]  # R3D uses a stem module
    
    # Create new first layer for single channel input
    new_first_conv = nn.Conv3d(
        1,  # Single channel for medical images
        64, 
        kernel_size=(3, 3, 3), 
        stride=(1, 1, 1), 
        padding=(1, 1, 1), 
        bias=False
    )
    
    # Initialize with pretrained weights
    with torch.no_grad():
        # Average the original weights across RGB channels to get single channel weights
        original_weights = original_first_conv.weight.data
        avg_weights = original_weights.mean(dim=1, keepdim=True)  # Average across input channels
        
        # Interpolate spatial dimensions from 7x7 to 3x3
        avg_weights = torch.nn.functional.interpolate(
            avg_weights, 
            size=(3, 3, 3),  # New kernel size for all dimensions
            mode='trilinear',  # Use trilinear for 3D interpolation
            align_corners=False
        )
        
        # Copy to new layer
        new_first_conv.weight.data = avg_weights
    
    # Replace the first convolution in the stem
    model.stem[0] = new_first_conv
    
    # Modify final layer for binary classification
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, NUM_CLASSES)
    
    return model

# ========== Swin_Transformer_Tiny ==========
def Swin_Transformer_Tiny():
    # Load Swin-Tiny WITHOUT pretrained weights
    model = models.swin_t(weights=None)  # No pretrained weights
    
    # Modify head for binary classification
    num_features = model.head.in_features
    model.head = nn.Linear(num_features, 2)
    
    return model

# ========== Swin_Transformer_Tiny (with pretrained weight) ==========
def Swin_Transformer_Tiny():
    # Load pretrained Swin-Tiny from torchvision
    model = models.swin_t(weights=Swin_T_Weights.IMAGENET1K_V1)
    
    # Modify head for number of classes
    num_features = model.head.in_features
    model.head = nn.Linear(num_features, NUM_CLASSES)
    
    return model

# ========== MobileViT_XXS ==========
def MobileViT_XXS():
    # Load smallest MobileViT (XXS) without pretrained weights
    model = timm.create_model(
        'mobilevit_xxs',
        pretrained=False,
        num_classes=NUM_CLASSES,
    )

    return model

# ========== MobileViT_XXS (with pretrained weights)==========
def MobileViT_XXS():
    # Load smallest MobileViT (XXS) WITH pretrained weights
    model = timm.create_model(
        'mobilevit_xxs',
        pretrained=True,  # Changed from False to True
        num_classes=NUM_CLASSES,
    )

    return model


# ========== 3D_Swin_Transformer_Tiny ==========
def 3D_Swin_Transformer_Tiny(num_classes = NUM_CLASSES):
    # Load pre-trained Swin Transformer Tiny for 3D data
    weights = Swin3D_T_Weights.DEFAULT
    model = swin3d_t(weights=weights)
    
    # Find the first Conv3d layer in the entire model
    def find_first_conv3d(module):
        for child in module.children():
            if isinstance(child, nn.Conv3d):
                return child
            result = find_first_conv3d(child)
            if result is not None:
                return result
        return None
    
    original_conv = find_first_conv3d(model)
    
    if original_conv is None:
        raise ValueError("Could not find Conv3d layer in the model")
    
    # Create new first layer for single channel input
    new_conv = nn.Conv3d(
        1,  # Single channel for medical images
        original_conv.out_channels, 
        kernel_size=original_conv.kernel_size,
        stride=original_conv.stride, 
        padding=original_conv.padding, 
        bias=original_conv.bias is not None
    )
    
    # Initialize with pretrained weights
    with torch.no_grad():
        original_weights = original_conv.weight.data
        avg_weights = original_weights.mean(dim=1, keepdim=True)
        new_conv.weight.data = avg_weights
        
        if original_conv.bias is not None:
            new_conv.bias.data = original_conv.bias.data
    
    # Replace the original convolution
    def replace_conv3d(module, old_conv, new_conv):
        for name, child in module.named_children():
            if child is old_conv:
                setattr(module, name, new_conv)
                return True
            if replace_conv3d(child, old_conv, new_conv):
                return True
        return False
    
    if not replace_conv3d(model, original_conv, new_conv):
        raise ValueError("Could not replace Conv3d layer")
    
    # Modify final classifier
    num_ftrs = model.head.in_features
    model.head = nn.Linear(num_ftrs, NUM_CLASSES)
    return model

#########################################################
#========== Segmentation Models ==========

# ========== Unet with ResNet18 Encoder ==========
def Unet():
    """Create a U-Net model with pretrained weights."""
    model = smp.Unet(
        encoder_name="resnet18",
        encoder_weights="imagenet",  # Use pretrained weights
        in_channels=3,
        classes=NUM_CLASSES,
    )
    return model


# ========== 3D Unet ==========
def 3D_Unet():
    """
    Create 3D UNet using MONAI library for hippocampus segmentation
    """
    model = monai_nets.UNet(
        spatial_dims=3,
        in_channels=1,  # Single channel for MRI
        out_channels=NUM_CLASSES,
        channels=(16, 32, 64, 128, 256),
        strides=(2, 2, 2, 2),
        num_res_units=2,
    )
    return model

# ========== Segformer with mit_b1 ==========
def Segformer():
    """Create a Segformer model with pretrained weights."""
    model = smp.Segformer(
        encoder_name="mit_b1",
        encoder_weights="imagenet",  # Use pretrained weights
        in_channels=3,
        classes=NUM_CLASSES,
    )
    return model

# ========== SwinUNETR  ==========
def SwinUNETR():
    """
    SwinUNETR with batch norm instead of instance norm for small images
    """
    model = monai_nets.SwinUNETR(
        img_size=(32, 32, 32),
        in_channels=1,
        out_channels=NUM_CLASSES,
        depths=(1, 1, 1, 1),
        num_heads=(2, 4, 8, 16),
        feature_size=12,
        norm_name='batch',  # Use batch norm instead of instance norm
        drop_rate=0.0,
        attn_drop_rate=0.0,
        dropout_path_rate=0.0,
        normalize=True,
        use_checkpoint=False,
        spatial_dims=3,
        downsample='merging',
        use_v2=True,
    )
    return model
