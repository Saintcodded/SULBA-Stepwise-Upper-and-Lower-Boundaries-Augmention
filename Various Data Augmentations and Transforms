import torch
import random
import numpy as np
import torchio as tio
from torchvision.transforms import v2
import torchvision.transforms as transforms
from torchvision.transforms.v2 import MixUp
from torchvision.transforms.v2 import CutMix
from torch.utils.data import default_collate
from torchvision.transforms import RandomApply, RandomRotation


class Cutout(object):
    """Randomly mask out one or more patches from an image.

    Args:
        n_holes (int): Number of patches to cut out of each image.
        length (int): The length (in pixels) of each square patch.
        p (float): Probability of applying the transformation. Default: 1.0.
    """
    def __init__(self, n_holes, length, p=1.0):
        self.n_holes = n_holes
        self.length = length
        self.p = p

    def __call__(self, img):
        """
        Args:
            img (Tensor): Tensor image of size (C, H, W).
        Returns:
            Tensor: Image with n_holes of dimension length x length cut out of it.
        """
        # ONLY ADDITION: Probability check
        if random.random() > self.p:
            return img
            
        # ORIGINAL CODE - NO CHANGES
        h = img.size(1)
        w = img.size(2)

        mask = torch.ones(h, w, dtype=torch.float32)

        for n in range(self.n_holes):
            y = random.randint(0, h - 1)
            x = random.randint(0, w - 1)

            y1 = max(0, y - self.length // 2)
            y2 = min(h, y + self.length // 2)
            x1 = max(0, x - self.length // 2)
            x2 = min(w, x + self.length // 2)

            mask[y1: y2, x1: x2] = 0.

        mask = mask.expand_as(img)
        img = img * mask

        return img


#========== Example Usage ==========
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Resize((64, 64)),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    Cutout(n_holes=1, length=(IMG_SIZE//4), p=1.0),  
])


###########################################################################
#========== CutMix and Mixup ==========

class MixUpWithProbability:
    def __init__(self, num_classes, p=1.0):
        self.p = p
        self.mixup = MixUp(num_classes=num_classes)

    def __call__(self, inputs, labels_onehot):
        if torch.rand(1).item() < self.p:
            return self.mixup(inputs, labels_onehot)
        return inputs, labels_onehot

class CutMixWithProbability:
    def __init__(self, num_classes, p=1.0):
        self.p = p
        self.cutmix = CutMix(num_classes=num_classes)

    def __call__(self, inputs, labels_onehot):
        if torch.rand(1).item() < self.p:
            return self.cutmix(inputs, labels_onehot)
        return inputs, labels_onehot


mixup_fn = MixUpWithProbability(NUM_CLASSES, 1.0)
cutmix_fn = CutMixWithProbability(NUM_CLASSES, p=1.0)

# Apply MixUp or CutMix
def collate_fn(batch):
    inputs, labels = default_collate(batch)
    labels_onehot = F.one_hot(
        labels.squeeze().long(),
        num_classes=NUM_CLASSES
    ).float()
    return mixup_fn(inputs, labels_onehot)
    #return cutmix_fn(inputs, labels_onehot)

dataloader = DataLoader(
    dataset,
    batch_size=64,
    collate_fn=collate_fn
)


###########################################################################
#========== 2D Data transforms ==========
transform_train = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),   # if image is grayscale and model uses pretrained weights
    #transforms.RandomHorizontalFlip(p = 0.5),
    #transforms.RandomVerticalFlip(p = 0.5),
    #RandomApply([RandomRotation((-90, 90))], p = 0.5),
    
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    #transforms.RandomErasing(p = 1.0),
    #Cutout(n_holes=1, length=(IMG_SIZE//4), p=1.0),,
    SULBA(task='classification', s=1, p=1.0),
])

transform_test = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])


#========== 3D Data transforms ========== (TorchIO transform handles both classification task and segmentation involving mask gracefully)

transform_train = tio.Compose([
    #Fixed Transfroms
    tio.Resize((IMG_SIZE, IMG_SIZE, IMG_SIZE)),
    tio.ToCanonical(),
    tio.ZNormalization(),
    tio.RescaleIntensity((-1, 1)),

    #Benchmark Transforms
    #tio.RandomAnisotropy(p = 0.5),
    #tio.RandomNoise(p = 0.5),
    #tio.RandomBiasField(p = 0.5),
    #tio.RandomBlur(p = 0.5),
    #tio.RandomElasticDeformation(
        #num_control_points=(5, 5, 5),    # Reduced from default 7 for 64 x64 x64 image size
        #max_displacement=(3, 3, 3),      # Reduced displacement for 64 x64 x64 image size
        #locked_borders=2,                # Prevent edge issues
        #p=1.0),
    #tio.RandomGamma(p = 0.5),
    #tio.RandomGhosting(p = 0.5),
    #tio.RandomSpike(p = 0.5),
    #tio.RandomFlip(p = 0.5),
    SULBA(task='classification', s=1, p=1.0),
])

transform_test = tio.Compose([
    tio.Resize((IMG_SIZE, IMG_SIZE, IMG_SIZE)),
    tio.ToCanonical(),
    tio.ZNormalization(),
    tio.RescaleIntensity((-1, 1)),
])
