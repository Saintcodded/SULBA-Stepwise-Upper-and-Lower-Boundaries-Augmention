import torch
import random
import numpy as np
import torchio as tio
from PIL import Image
from torchvision.transforms import v2
import torchvision.transforms as transforms
from torchvision.transforms.v2 import MixUp
from torchvision.transforms.v2 import CutMix
from torch.utils.data import default_collate
from torchvision.transforms import functional as F
from torchvision.transforms import InterpolationMode
from torchvision.transforms import RandomApply, RandomRotation

###############################################################
# ========== Image only Transforms ==========
###############################################################

# ========== Cutout ========== 
class Cutout(object):
    """Randomly mask out one or more patches from an image.

    Args:
        n_holes (int): Number of patches to cut out of each image.
        length (int): The length (in pixels) of each square patch.
        p (float): Probability of applying the transformation. Default: 1.0.
    """
    def __init__(self, n_holes, length, p=1.0):
        self.n_holes = n_holes
        self.length = length
        self.p = p

    def __call__(self, img):
        """
        Args:
            img (Tensor): Tensor image of size (C, H, W).
        Returns:
            Tensor: Image with n_holes of dimension length x length cut out of it.
        """
        if random.random() > self.p:
            return img
            
        h = img.size(1)
        w = img.size(2)

        mask = torch.ones(h, w, dtype=torch.float32)

        for n in range(self.n_holes):
            y = random.randint(0, h - 1)
            x = random.randint(0, w - 1)

            y1 = max(0, y - self.length // 2)
            y2 = min(h, y + self.length // 2)
            x1 = max(0, x - self.length // 2)
            x2 = min(w, x + self.length // 2)

            mask[y1: y2, x1: x2] = 0.

        mask = mask.expand_as(img)
        img = img * mask

        return img


# ========== Example Usage ==========
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Resize((64, 64)),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    Cutout(n_holes=1, length=(IMG_SIZE//4), p=1.0),  
])


###########################################################################
#========== CutMix and Mixup ==========

class MixUpWithProbability:
    def __init__(self, num_classes, p=1.0):
        self.p = p
        self.mixup = MixUp(num_classes=num_classes)

    def __call__(self, inputs, labels_onehot):
        if torch.rand(1).item() < self.p:
            return self.mixup(inputs, labels_onehot)
        return inputs, labels_onehot

class CutMixWithProbability:
    def __init__(self, num_classes, p=1.0):
        self.p = p
        self.cutmix = CutMix(num_classes=num_classes)

    def __call__(self, inputs, labels_onehot):
        if torch.rand(1).item() < self.p:
            return self.cutmix(inputs, labels_onehot)
        return inputs, labels_onehot


mixup_fn = MixUpWithProbability(NUM_CLASSES, 1.0)
cutmix_fn = CutMixWithProbability(NUM_CLASSES, p=1.0)

# Apply MixUp or CutMix
def collate_fn(batch):
    inputs, labels = default_collate(batch)
    labels_onehot = F.one_hot(
        labels.squeeze().long(),
        num_classes=NUM_CLASSES
    ).float()
    return mixup_fn(inputs, labels_onehot)
    #return cutmix_fn(inputs, labels_onehot)

dataloader = DataLoader(
    dataset,
    batch_size=64,
    collate_fn=collate_fn
)

###########################################################################
#========== Other 2D image only Data transforms ==========
transform_train = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),   # if image is grayscale and model uses pretrained weights
    #transforms.RandomHorizontalFlip(p = 0.5),
    #transforms.RandomVerticalFlip(p = 0.5),
    #RandomApply([RandomRotation((-180, 180))], p = 0.5),
    
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    #transforms.RandomErasing(p = 0.5),
    #Cutout(n_holes=1, length=(IMG_SIZE//4), p=0.5),,
    SULBA(task='classification', s=1, p=1.0),
])

transform_test = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

###########################################################################
#========== 2D Segmentation Data transforms (image and msk) ==========
###########################################################################

# ========== Horizontal Flip, Vertical Flip, Rotation (image and mask) ==========
class SynchronizedAugmentation:
    def __init__(self, augmentations=None, rotation_range=(-180, 180)):
        self.augmentations = {
            'h_flip_p': 0.5,
            'v_flip_p': 0.5,
            'rotation_p': 0.5,
        }
        if augmentations:
            self.augmentations.update(augmentations)

        self.rotation_range = rotation_range

    def __call__(self, image, mask):
        if isinstance(image, np.ndarray):
            image = Image.fromarray(image)
        if isinstance(mask, np.ndarray):
            mask = Image.fromarray(mask)

        # Horizontal flip
        if random.random() < self.augmentations['h_flip_p']:
            image = F.hflip(image)
            mask = F.hflip(mask)

        # Vertical flip
        if random.random() < self.augmentations['v_flip_p']:
            image = F.vflip(image)
            mask = F.vflip(mask)

        # Rotation
        if random.random() < self.augmentations['rotation_p']:
            angle = random.uniform(*self.rotation_range)
            image = F.rotate(
                image,
                angle,
                interpolation=InterpolationMode.BILINEAR,
                fill=0
            )
            mask = F.rotate(
                mask,
                angle,
                interpolation=InterpolationMode.NEAREST,
                fill=0
            )

        return np.array(image), np.array(mask)

#========== Cutout (Image and Mask) ==========
class Cutout_image_mask:
    """
    Cutout augmentation for image–mask pairs (segmentation).

    Args:
        n_holes (int): Number of cutout regions.
        length (int): Side length of each square region.
    """
    def __init__(self, n_holes, length):
        self.n_holes = n_holes
        self.length = length

    def __call__(self, img, mask, p=1.0):
        """
        Args:
            img (Tensor): Image tensor of shape (C, H, W)
            mask (Tensor): Mask tensor of shape (H, W) or (1, H, W)
            p (float): Probability of applying Cutout
        """
        # ---- Standard probability application ----
        if random.random() > p:
            return img, mask

        # Ensure mask has shape (1, H, W)
        if mask.dim() == 2:
            mask = mask.unsqueeze(0)

        _, h, w = img.shape

        cutout_mask = np.ones((h, w), dtype=np.float32)

        for _ in range(self.n_holes):
            y = np.random.randint(0, h)
            x = np.random.randint(0, w)

            y1 = np.clip(y - self.length // 2, 0, h)
            y2 = np.clip(y + self.length // 2, 0, h)
            x1 = np.clip(x - self.length // 2, 0, w)
            x2 = np.clip(x + self.length // 2, 0, w)

            cutout_mask[y1:y2, x1:x2] = 0.0

        cutout_mask = torch.from_numpy(cutout_mask).to(img.device)

        # Apply SAME spatial mask to image and segmentation mask
        img = img * cutout_mask.unsqueeze(0)
        mask = mask * cutout_mask.unsqueeze(0)

        return img, mask.squeeze(0)

# ========== Example Usage ==========
cutout = Cutout_image_mask(n_holes=1, length=(IMG_SIZE//4))

image_tensor, mask_tensor = cutout(
    image_tensor,
    mask_tensor,
    p=0.5
)

# ========== Random Erasing (Image and Mask) ==========
class RandomErasing_image_mask:
    """
    Randomly erases a rectangular region in both image and mask
    using identical spatial parameters.

    Args:
        scale (tuple): Range of proportion of erased area.
        ratio (tuple): Range of aspect ratio.
        value (int | float | list | "random"): Image erase value.
        mask_value (int | float | list): Mask erase value.
    """

    def __init__(self, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, mask_value=0):
        self.scale = scale
        self.ratio = ratio
        self.value = value
        self.mask_value = mask_value

    def get_params(self, img, scale, ratio, value=None):
        _, img_h, img_w = img.shape
        area = img_h * img_w

        log_ratio = torch.log(torch.tensor(ratio))
        for _ in range(10):
            erase_area = area * torch.empty(1).uniform_(scale[0], scale[1]).item()
            aspect_ratio = torch.exp(
                torch.empty(1).uniform_(log_ratio[0], log_ratio[1])
            ).item()

            h = int(round(math.sqrt(erase_area * aspect_ratio)))
            w = int(round(math.sqrt(erase_area / aspect_ratio)))

            if h < img_h and w < img_w:
                i = torch.randint(0, img_h - h + 1, (1,)).item()
                j = torch.randint(0, img_w - w + 1, (1,)).item()

                if value is None:
                    v = torch.empty((img.shape[0], h, w), device=img.device).normal_()
                else:
                    v = torch.tensor(value, device=img.device)[:, None, None]

                return i, j, h, w, v

        # fallback → no-op
        return None

    def __call__(self, img, mask, p=1.0):
        """
        Args:
            img (Tensor): (C, H, W)
            mask (Tensor): (H, W) or (1, H, W)
            p (float): Probability of applying random erasing
        """
        # ---- Standard probability application ----
        if random.random() > p:
            return img, mask

        if mask.dim() == 2:
            mask = mask.unsqueeze(0)

        # Resolve erase value
        if isinstance(self.value, str) and self.value == "random":
            value = None
        elif isinstance(self.value, (int, float)):
            value = [float(self.value)]
        else:
            value = self.value

        params = self.get_params(img, self.scale, self.ratio, value)
        if params is None:
            return img, mask.squeeze(0)

        x, y, h, w, v = params

        # Mask erase value
        if isinstance(self.mask_value, (int, float)):
            mask_v = torch.full_like(v, float(self.mask_value))
        else:
            mask_v = torch.tensor(self.mask_value, device=img.device)[:, None, None]

        # Apply erasing
        img = img.clone()
        mask = mask.clone()

        img[..., x:x+h, y:y+w] = v
        mask[..., x:x+h, y:y+w] = mask_v

        return img, mask.squeeze(0)

# ========== Example Usage ==========
random_erasing = RandomErasing_image_mask(
    scale=(0.02, 0.33),
    ratio=(0.3, 3.3),
    value=0,
    mask_value=0
)

image_tensor, mask_tensor = random_erasing(
    image_tensor,
    mask_tensor,
    p=0.5
)

####################################################################################
# ========== Combined Example Usage (Fliping, Rotation, Cutout, Random Erasing) ==========
####################################################################################
#apply transforms
def train_transform_func(image, mask):
    """Transform function for training with synchronized image-mask pairs augmentation"""

    # standard augmentations (Horizontal Flip, Vertical Flip and Rotation)
    #image, mask = SynchronizedAugmentation(image, mask)

    # Convert to tensors 
    image_tensor = transforms.ToTensor()(image)
    mask_tensor = torch.from_numpy(mask).long()

    # Apply Cutout augmentation
    #image, mask = cutout(image_tensor, mask_tensor, p=0.5)

    # Apply random erasing
    #image, mask = random_erase(image_tensor, mask_tensor, p=0.5)
    
    # Apply SULBA2D augmentation
    image, mask= SULBA(task='segmentation', s=1, p=1.0)(image_tensor, mask_tensor)

    return image, mask

# ========== CutMix (Image and Mask) ==========
class CutMix_image_mask(object):
    """Apply CutMix at the batch level for both images and masks.
       while maintaining image-mask consistency.
    """
    
    def __init__(self, alpha=1.0, p=0.5):
        self.alpha = alpha
        self.p = p
        
    def _get_cutmix_params(self, batch_size, H, W):
        """Get CutMix parameters for a batch."""
        lam = torch.distributions.Beta(self.alpha, self.alpha).sample().item()
        
        r_x = torch.randint(0, W, (1,)).item()
        r_y = torch.randint(0, H, (1,)).item()
        
        r = 0.5 * math.sqrt(1.0 - lam)
        r_w_half = int(r * W)
        r_h_half = int(r * H)
        
        x1 = max(0, r_x - r_w_half)
        y1 = max(0, r_y - r_h_half)
        x2 = min(W, r_x + r_w_half)
        y2 = min(H, r_y + r_h_half)
        
        indices = torch.randperm(batch_size)
        
        return (x1, y1, x2, y2), lam, indices
    
    def __call__(self, images, masks):
        """
        Apply CutMix to batch with probability p.
        """
        if random.random() > self.p:
            return images, masks
            
        batch_size, _, H, W = images.shape
        
        # Ensure masks have proper dimensions
        if masks.dim() == 3:
            masks = masks.unsqueeze(1)
        
        box, lam, indices = self._get_cutmix_params(batch_size, H, W)
        x1, y1, x2, y2 = box
        
        # Create mixed batch
        mixed_images = images.clone()
        mixed_masks = masks.clone()
        
        # Apply the same CutMix to both images and masks
        mixed_images[:, :, y1:y2, x1:x2] = images[indices, :, y1:y2, x1:x2]
        mixed_masks[:, :, y1:y2, x1:x2] = masks[indices, :, y1:y2, x1:x2]
        
        return mixed_images, mixed_masks.squeeze(1)

# ========== MixUp (Image and Mask) ==========
class MixUp_image_mask(object):
    """Apply MixUp at the batch level for both images and masks."""
    
    def __init__(self, alpha=1.0, p=0.5):
        self.alpha = alpha
        self.p = p
        self.dist = torch.distributions.Beta(alpha, alpha)
        
    def _get_mixup_params(self, batch_size):
        """Get MixUp parameters for a batch."""
        lam = float(self.dist.sample(()))
        indices = torch.randperm(batch_size)
        return lam, indices
    
    def __call__(self, images, masks):
        """
        Apply MixUp to batch with probability p.
        """
        if random.random() > self.p:
            return images, masks
            
        batch_size = images.shape[0]
        
        # Ensure masks have proper dimensions
        if masks.dim() == 3:
            masks = masks.unsqueeze(1)
        
        # Get MixUp parameters
        lam, indices = self._get_mixup_params(batch_size)
        
        # Apply MixUp to images
        mixed_images = images * lam + images[indices] * (1.0 - lam)
        
        # For masks, create a binary choice for each sample
        # Use the same random decision for all pixels in each sample
        choice = torch.rand(batch_size, 1, 1, 1, device=images.device) < lam
        
        # Use torch.where to select between original and mixed masks
        # This preserves the integer dtype
        mixed_masks = torch.where(choice, masks, masks[indices])
        
        return mixed_images, mixed_masks.squeeze(1)
        
# Create CutMix instance
cutmix = CutMix_image_mask(alpha=1.0, p=1.0)
mixup = MixUp_image_mask(alpha=1.0, p=1.0)

# Example Usage
# Apply CutMix at batch level  (can be called within the training loop)
images, masks = cutmix(images, masks)
images, masks = mixup(images, masks)

# Add channel dimension if missing (FIX for dimension mismatch)
if masks.dim() == 3:  # [B, H, W] format
    masks = masks.unsqueeze(1)  # Convert to [B, 1, H, W]


#========== 3D Data transforms ========== (TorchIO transform handles both classification task and segmentation involving mask gracefully)

transform_train = tio.Compose([
    #Fixed Transfroms
    tio.Resize((IMG_SIZE, IMG_SIZE, IMG_SIZE)),
    tio.ToCanonical(),
    tio.ZNormalization(),
    tio.RescaleIntensity((-1, 1)),

    #Benchmark Transforms
    #tio.RandomAnisotropy(p = 0.5),
    #tio.RandomNoise(p = 0.5),
    #tio.RandomBiasField(p = 0.5),
    #tio.RandomBlur(p = 0.5),
    #tio.RandomElasticDeformation(
        #num_control_points=(5, 5, 5),    # Reduced from default 7 for 64 x64 x64 image size
        #max_displacement=(3, 3, 3),      # Reduced displacement for 64 x64 x64 image size
        #locked_borders=2,                # Prevent edge issues
        #p=1.0),
    #tio.RandomGamma(p = 0.5),
    #tio.RandomGhosting(p = 0.5),
    #tio.RandomSpike(p = 0.5),
    #tio.RandomFlip(p = 0.5),
    SULBA(task='classification', s=1, p=1.0),
])

transform_test = tio.Compose([
    tio.Resize((IMG_SIZE, IMG_SIZE, IMG_SIZE)),
    tio.ToCanonical(),
    tio.ZNormalization(),
    tio.RescaleIntensity((-1, 1)),
])
